import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from utils.common import linear_projection, calculate_entropy

def render_multihead_visualization(analyze, src_tokens, tgt_tokens, src_E, tgt_E, Wq, Wk, Wv, dim):
    """ë©€í‹°í—¤ë“œ ì‹œê°í™” íƒ­ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    
    st.subheader("ğŸ§© Multi-Head Attention ì‹œê°í™”")
    st.markdown("""
    í•œ ë²ˆì˜ ì–´í…ì…˜ì´ í•œ ê°€ì§€ ì¢…ë¥˜ì˜ ê´€ê³„ë§Œ ë³¸ë‹¤ë©´, ì—¬ëŸ¬ ë²ˆì˜ ì–´í…ì…˜ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ê³„(ì˜ˆ: ë¬¸ë²•ì  ê´€ê³„, ì˜ë¯¸ì  ê´€ê³„ ë“±)ë¥¼ ë™ì‹œì— íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ **ë©€í‹°í—¤ë“œ ì–´í…ì…˜**ì˜ í•µì‹¬ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤.
    
    **ê³¼ì •:**
    1. **ë¶„í• (Split)**: ê¸°ì¡´ì˜ Q, K, Vë¥¼ ì—¬ëŸ¬ ê°œ('í—¤ë“œ'ì˜ ìˆ˜ë§Œí¼)ì˜ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    2. **ë³‘ë ¬ ì–´í…ì…˜(Parallel Attention)**: ê° ì¡°ê°(í—¤ë“œ)ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ Scaled Dot-Product ì–´í…ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê° í—¤ë“œëŠ” ì„œë¡œ ë‹¤ë¥¸ ì–´í…ì…˜ íŒ¨í„´ì„ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤.
    3. **ê²°í•©(Concatenate)**: ê° í—¤ë“œì—ì„œ ë‚˜ì˜¨ ê²°ê³¼(Context Vector)ë“¤ì„ ë‹¤ì‹œ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
    4. **ìµœì¢… ë³€í™˜(Final Projection)**: í•©ì³ì§„ ë²¡í„°ë¥¼ ìµœì¢… ì¶œë ¥ ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì„ í˜• ë ˆì´ì–´ë¥¼ í†µê³¼ì‹œí‚µë‹ˆë‹¤.
    """)
    st.latex(r"\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O \quad \text{where head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)")
    
    if analyze:
        st.markdown("---")
        
        # í—¤ë“œ ìˆ˜ ì„ íƒ
        # ë™ì  í‚¤ ìƒì„±ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€
        if 'multihead_counter' not in st.session_state:
            st.session_state.multihead_counter = 0
        st.session_state.multihead_counter += 1
        
        num_heads = st.slider("í—¤ë“œ ìˆ˜ ì„ íƒ", min_value=1, max_value=8, value=4, help="ë¶„ì„í•  í—¤ë“œì˜ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", key=f"multihead_num_heads_slider_{st.session_state.multihead_counter}")
        
        st.markdown(f"### ğŸ¯ ë©€í‹°í—¤ë“œ í¬ë¡œìŠ¤ ì–´í…ì…˜ ì˜ˆì‹œ (Heads = {num_heads})")
        
        head_dim = dim // num_heads
        
        # í¸ì˜ìƒ, ê¸°ì¡´ Q,K,Vë¥¼ ë¶„í• í•˜ì—¬ ì‚¬ìš©
        Qd = linear_projection(tgt_E, Wq)
        Ks = linear_projection(src_E, Wk)
        Vs = linear_projection(src_E, Wv)
        
        # 1. ë¶„í•  (reshape)
        # (len, dim) -> (len, num_heads, head_dim) -> (num_heads, len, head_dim)
        Qd_heads = Qd.reshape(len(tgt_tokens), num_heads, head_dim).transpose(1, 0, 2)
        Ks_heads = Ks.reshape(len(src_tokens), num_heads, head_dim).transpose(1, 0, 2)
        Vs_heads = Vs.reshape(len(src_tokens), num_heads, head_dim).transpose(1, 0, 2)
        
        st.write(f"**1. ë¶„í• **: Q, K, Vë¥¼ ê°ê° `{num_heads}`ê°œì˜ í—¤ë“œë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.")
        st.write(f" - ì›ë³¸ Q shape: `{Qd.shape}` -> í—¤ë“œë³„ Q shape: `{Qd_heads.shape}` (num_heads, len, head_dim)")
        st.write(f" - ê° í—¤ë“œì˜ ì°¨ì›: `{head_dim}` (ì›ë³¸ ì°¨ì› `{dim}` Ã· í—¤ë“œ ìˆ˜ `{num_heads}`)")
        
        # 2. ë³‘ë ¬ ì–´í…ì…˜ & ì‹œê°í™”
        st.write(f"**2. ë³‘ë ¬ ì–´í…ì…˜**: ê° í—¤ë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ì–´í…ì…˜ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")
        
        # í—¤ë“œë³„ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì €ì¥
        head_weights = []
        head_outputs = []
        
        # í—¤ë“œë³„ ê°œë³„ í”Œë¡¯ìœ¼ë¡œ í‘œì‹œ
        for i in range(num_heads):
            # ê°„ë‹¨í•œ ì–´í…ì…˜ ê³„ì‚° (ì‹¤ì œ scaled_dot_product_attention í•¨ìˆ˜ ëŒ€ì‹ )
            scores = Qd_heads[i] @ Ks_heads[i].T / np.sqrt(head_dim)
            weights = softmax(scores, axis=-1)
            context = weights @ Vs_heads[i]
            
            head_outputs.append(context)
            head_weights.append(weights)
            
            # ê°œë³„ í”Œë¡¯
            fig, ax = plt.subplots(figsize=(6, 5))
            im = ax.imshow(weights, cmap='viridis')
            ax.set_xticks(np.arange(len(src_tokens)))
            ax.set_yticks(np.arange(len(tgt_tokens)))
            ax.set_xticklabels(src_tokens, rotation=45, ha="right", fontsize=10)
            ax.set_yticklabels(tgt_tokens, fontsize=10)
            ax.set_title(f"Head {i+1} Attention Weights", fontsize=12)
            ax.set_xlabel("Source Tokens (í•œêµ­ì–´)", fontsize=10)
            ax.set_ylabel("Target Tokens (ì˜ì–´)", fontsize=10)
            
            # ê°’ ì£¼ì„ (í—¤ë“œê°€ ë§ìœ¼ë©´ ìƒëµ)
            if num_heads <= 4:
                for y in range(len(tgt_tokens)):
                    for x in range(len(src_tokens)):
                        ax.text(x, y, f"{weights[y, x]:.2f}", ha="center", va="center", fontsize=8)
            
            # ì»¬ëŸ¬ë°” ì¶”ê°€
            plt.colorbar(im, ax=ax, shrink=0.8)
            st.pyplot(fig)
            plt.close(fig)  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê·¸ë˜í”„ ìë™ ì •ë¦¬
            
            # í—¤ë“œë³„ í†µê³„ ì •ë³´
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric(f"Head {i+1} í‰ê·  ì–´í…ì…˜", f"{np.mean(weights):.4f}")
            with col2:
                st.metric(f"Head {i+1} ìµœëŒ€ ì–´í…ì…˜", f"{np.max(weights):.4f}")
            with col3:
                st.metric(f"Head {i+1} ì—”íŠ¸ë¡œí”¼", f"{calculate_entropy(weights):.4f}")
            
            st.markdown("---")

        # 3. í—¤ë“œ ê°„ ë¹„êµ ë¶„ì„
        st.markdown("### ğŸ” í—¤ë“œ ê°„ ë¹„êµ ë¶„ì„")
        
        # ëª¨ë“  í—¤ë“œì˜ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ í•˜ë‚˜ì˜ íˆíŠ¸ë§µìœ¼ë¡œ ë¹„êµ
        if num_heads > 1:
            # í‰ê·  ì–´í…ì…˜ ê°€ì¤‘ì¹˜
            avg_weights = np.mean(head_weights, axis=0)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            im = ax.imshow(avg_weights, cmap='viridis')
            ax.set_xticks(np.arange(len(src_tokens)))
            ax.set_yticks(np.arange(len(tgt_tokens)))
            ax.set_xticklabels(src_tokens, rotation=45, ha="right", fontsize=10)
            ax.set_yticklabels(tgt_tokens, fontsize=10)
            ax.set_title(f"í‰ê·  ì–´í…ì…˜ ê°€ì¤‘ì¹˜ (ëª¨ë“  í—¤ë“œ)", fontsize=12)
            ax.set_xlabel("Source Tokens (í•œêµ­ì–´)", fontsize=10)
            ax.set_ylabel("Target Tokens (ì˜ì–´)", fontsize=10)
            
            # ê°’ ì£¼ì„
            for y in range(len(tgt_tokens)):
                for x in range(len(src_tokens)):
                    ax.text(x, y, f"{avg_weights[y, x]:.2f}", ha="center", va="center", fontsize=8)
            
            plt.colorbar(im, ax=ax)
            st.pyplot(fig)
            plt.close(fig)  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê·¸ë˜í”„ ìë™ ì •ë¦¬
            
            # í—¤ë“œ ê°„ ìœ ì‚¬ë„ ë¶„ì„
            st.markdown("### ğŸ“Š í—¤ë“œ ê°„ ìœ ì‚¬ë„ ë¶„ì„")
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = np.zeros((num_heads, num_heads))
            for i in range(num_heads):
                for j in range(num_heads):
                    if i == j:
                        similarities[i, j] = 1.0
                    else:
                        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ í‰ë©´í™”í•˜ì—¬ ìœ ì‚¬ë„ ê³„ì‚°
                        flat_i = head_weights[i].flatten()
                        flat_j = head_weights[j].flatten()
                        cos_sim = np.dot(flat_i, flat_j) / (np.linalg.norm(flat_i) * np.linalg.norm(flat_j))
                        similarities[i, j] = cos_sim
            
            # ìœ ì‚¬ë„ íˆíŠ¸ë§µ
            fig, ax = plt.subplots(figsize=(6, 5))
            im = ax.imshow(similarities, cmap='RdYlBu_r', vmin=-1, vmax=1)
            ax.set_xticks(np.arange(num_heads))
            ax.set_yticks(np.arange(num_heads))
            ax.set_xticklabels([f"Head {i+1}" for i in range(num_heads)])
            ax.set_yticklabels([f"Head {i+1}" for i in range(num_heads)])
            ax.set_title("í—¤ë“œ ê°„ ìœ ì‚¬ë„ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)", fontsize=12)
            
            # ê°’ ì£¼ì„
            for i in range(num_heads):
                for j in range(num_heads):
                    ax.text(j, i, f"{similarities[i, j]:.2f}", ha="center", va="center", fontsize=10)
            
            plt.colorbar(im, ax=ax)
            st.pyplot(fig)
            plt.close(fig)  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê·¸ë˜í”„ ìë™ ì •ë¦¬
            
            # ìœ ì‚¬ë„ í•´ì„
            st.markdown("**ìœ ì‚¬ë„ í•´ì„:**")
            st.markdown("- **ë†’ì€ ìœ ì‚¬ë„ (0.7~1.0)**: ë‘ í—¤ë“œê°€ ë¹„ìŠ·í•œ íŒ¨í„´ì„ í•™ìŠµ")
            st.markdown("- **ì¤‘ê°„ ìœ ì‚¬ë„ (0.3~0.7)**: ë‘ í—¤ë“œê°€ ë¶€ë¶„ì ìœ¼ë¡œ ìœ ì‚¬í•œ íŒ¨í„´")
            st.markdown("- **ë‚®ì€ ìœ ì‚¬ë„ (-0.3~0.3)**: ë‘ í—¤ë“œê°€ ì„œë¡œ ë‹¤ë¥¸ íŒ¨í„´ì„ í•™ìŠµ")
            st.markdown("- **ìŒì˜ ìœ ì‚¬ë„ (-1.0~-0.3)**: ë‘ í—¤ë“œê°€ ë°˜ëŒ€ íŒ¨í„´ì„ í•™ìŠµ")
        
        # 4. ë©€í‹°í—¤ë“œ íš¨ê³¼ ì„¤ëª…
        st.markdown("### ğŸ­ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì˜ íš¨ê³¼")
        st.markdown("""
        **ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤:**
        
        - **ë‹¤ì–‘ì„±**: ê° í—¤ë“œê°€ ì„œë¡œ ë‹¤ë¥¸ ê´€ê³„ë¥¼ í•™ìŠµ
        - **ì•ˆì •ì„±**: ë‹¨ì¼ í—¤ë“œì˜ ì‹¤íŒ¨ê°€ ì „ì²´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ìµœì†Œí™”
        - **í‘œí˜„ë ¥**: ë³µì¡í•œ ê´€ê³„ë¥¼ ë” ì˜ ëª¨ë¸ë§
        - **ë³‘ë ¬í™”**: ì—¬ëŸ¬ í—¤ë“œë¥¼ ë™ì‹œì— ê³„ì‚° ê°€ëŠ¥
        
        **ì‹¤ì œ ì˜ˆì‹œ:**
        - **Head 1**: ì£¼ì–´-ë™ì‚¬ ê´€ê³„ì— ì§‘ì¤‘
        - **Head 2**: í˜•ìš©ì‚¬-ëª…ì‚¬ ê´€ê³„ì— ì§‘ì¤‘
        - **Head 3**: ì „ì¹˜ì‚¬-ëª…ì‚¬ ê´€ê³„ì— ì§‘ì¤‘
        - **Head 4**: ì „ì²´ì ì¸ ë¬¸ë§¥ ê´€ê³„ì— ì§‘ì¤‘
        """)
    
    else:
        st.warning("ë¨¼ì € 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

def softmax(x, axis=-1):
    """ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜"""
    x = x - np.max(x, axis=axis, keepdims=True)
    ex = np.exp(x)
    return ex / np.sum(ex, axis=axis, keepdims=True)
